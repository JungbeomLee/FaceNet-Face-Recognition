{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":["Pf1FKFDprYd_","9Bt5-CoDsNLJ","BszUUTaMsSSa","YbxrXQpsrdil"],"authorship_tag":"ABX9TyMt1kNIc5XsebQjlDziwV56"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 기본 세팅"],"metadata":{"id":"Pf1FKFDprYd_"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"lxKyc6-Cjem9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 기본 세팅"],"metadata":{"id":"9Bt5-CoDsNLJ"}},{"cell_type":"code","source":["import tensorflow as tf\n","import PIL\n","import numpy as np\n","import os\n","import cv2\n","from google.colab.patches import cv2_imshow"],"metadata":{"id":"w_Lz1hNWuUeV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://jkisaaclee.kro.kr/keras/facenet/deep%20learning/computer%20vision/2019/10/01/how_to_develop_a_face_recognition_system_using_facenet_in_keras_ko/\n","# https://machinelearningmastery.com/how-to-develop-a-face-recognition-system-using-facenet-in-keras-and-an-svm-classifier/"],"metadata":{"id":"LnpuEWiLn6yV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = tf.keras.models.load_model('/content/drive/MyDrive/A.아이/github/models_folder/facenet/facenet_model.h5')"],"metadata":{"id":"IZcuWwMDsoTz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model.input)\n","print(model.output)"],"metadata":{"id":"fk1NfRxzs9Nd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install mediapipe"],"metadata":{"id":"wAyayPJPtNQd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["friends_path_first = '/content/drive/MyDrive/A.아이/images/friends_image/fist_image/'\n","friends_path_first_name = os.listdir(friends_path_first)\n","\n","friends_path_second = '/content/drive/MyDrive/A.아이/images/friends_image/second_image/'\n","friends_path_second_name = os.listdir(friends_path_second)"],"metadata":{"id":"1QKnFP4eog2t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import mediapipe as mp\n","\n","mp_face_detection = mp.solutions.face_detection\n","image_friends_first_list = []\n","label_first_list = []\n","margin = 0.15  # Adjust this value to change the cropping margin\n","\n","for name in friends_path_first_name :\n","    img = cv2.imread(friends_path_first + name)\n","    with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5) as face_detection:\n","            face = face_detection.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","            if face.detections:\n","                for i, detection in enumerate(face.detections):\n","                    # Get bounding box coordinates\n","                    box = detection.location_data.relative_bounding_box\n","                    ih, iw, _ = img.shape\n","                    x, y, w, h = int(box.xmin * iw), int(box.ymin * ih), int(box.width * iw), int(box.height * ih)\n","\n","                    # Calculate margins for x, y, w, h\n","                    mx = int(w * margin)\n","                    my = int(h * margin)\n","\n","                    # Crop the face with margins\n","                    face_image = img[y+my:y+h-my, x+mx:x+w-mx]\n","                    if face_image.size != 0:\n","                        # Resize the image to 105x105\n","                        face_image = cv2.resize(face_image, (160, 160))\n","                        face_image = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)\n","                    else :\n","                        break\n","            else :\n","                print('cant find face')\n","                continue\n","    image_friends_first_list.append(face_image)\n","    label = name.split('_')[0]\n","    label_first_list.append(label)\n","\n","for i in image_friends_first_list :\n","    cv2_imshow(i)\n"],"metadata":{"id":"NHxFrUqvqO4-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mp_face_detection = mp.solutions.face_detection\n","image_friends_second_list = []\n","label_second_list = []\n","margin = 0.15  # Adjust this value to change the cropping margin\n","\n","for name in friends_path_second_name :\n","    img = cv2.imread(friends_path_second + name)\n","    with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5) as face_detection:\n","            face = face_detection.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","            if face.detections:\n","                for i, detection in enumerate(face.detections):\n","                    # Get bounding box coordinates\n","                    box = detection.location_data.relative_bounding_box\n","                    ih, iw, _ = img.shape\n","                    x, y, w, h = int(box.xmin * iw), int(box.ymin * ih), int(box.width * iw), int(box.height * ih)\n","\n","                    # Calculate margins for x, y, w, h\n","                    mx = int(w * margin)\n","                    my = int(h * margin)\n","\n","                    # Crop the face with margins\n","                    face_image = img[y+my:y+h-my, x+mx:x+w-mx]\n","                    if face_image.size != 0:\n","                        # Resize the image to 105x105\n","                        face_image = cv2.resize(face_image, (160, 160))\n","                        face_image = cv2.cvtColor(face_image, cv2.COLOR_RGB2GRAY)\n","                    else :\n","                        break\n","            else :\n","                print('cant find face')\n","                continue\n","    image_friends_second_list.append(face_image)\n","    label = name.split('_')[0]\n","    label_second_list.append(label)\n","\n","\n","for count,i in enumerate(image_friends_second_list) :\n","    print(count)\n","    cv2_imshow(i)\n"],"metadata":{"id":"a1Sxs3FhoaXV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["label_first_list"],"metadata":{"id":"eN0hSi4cuTez"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_friends_first_list = np.array(image_friends_first_list)\n","image_friends_second_list = np.array(image_friends_second_list)\n","\n","image_friends_first_list.shape, image_friends_second_list.shape"],"metadata":{"id":"EPcy35n2qsJo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["face_embeding_model = tf.keras.models.load_model('/content/drive/MyDrive/A.아이/github/models_folder/facenet/facenet_model.h5')"],"metadata":{"id":"i7BC9mh7quVs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 간단 테스트"],"metadata":{"id":"BszUUTaMsSSa"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def get_face_embedding_ver1(image, model):\n","    # Preprocess the image\n","    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n","    image = np.expand_dims(image, axis=0)  # Add batch dimension\n","    image = image.astype('float32') / 255  # Normalize to [0,1]\n","\n","    # Compute embedding\n","    embedding = model.predict(image)[0]\n","    return embedding\n","\n","def test_model_with_friends_ver1(index, image_friends_first_list, image_friends_second_list, model):\n","    # Get the embedding for the anchor image\n","    anchor_embedding = get_face_embedding_ver1(image_friends_first_list[index], model)\n","\n","    # Variables to keep track of most similar images\n","    most_similar_images = []  # A list to keep track of the indices of the most similar images\n","    distances = []  # A list to keep track of the distances\n","\n","    # Iterate over images to compute distances\n","    for i, image in enumerate(image_friends_second_list):\n","        # Get the embedding for this image\n","        image_embedding = get_face_embedding_ver1(image, model)\n","\n","        # Compute the distance\n","        distance = np.linalg.norm(anchor_embedding - image_embedding)\n","        distances.append(distance)\n","\n","    # Compute min and max distances\n","    min_distance = min(distances)\n","    max_distance = max(distances)\n","\n","    # Normalize distances and compute similarities\n","    for i, distance in enumerate(distances):\n","        # Normalize the distance to [0,1] using the min and max distances\n","        normalized_distance = (distance - 0) / (max_distance - 0)\n","\n","        # Convert to percentage\n","        percentage = (1 - normalized_distance) * 100\n","\n","        # Compute the similarity (as 1 - normalized Euclidean distance)\n","        similarity = percentage\n","\n","        # Add new image\n","        most_similar_images.append((i, similarity))  # Keeping track of the index and similarity\n","\n","    # Sort the images by similarity\n","    most_similar_images.sort(key=lambda x: x[1], reverse=True)\n","\n","    # Show the anchor image\n","    plt.figure(figsize=(20, 4))\n","    plt.subplot(1, 6, 1)\n","    plt.imshow(image_friends_first_list[index])\n","    plt.title(\"Anchor image\")\n","    plt.axis('off')\n","\n","    # Show the most similar images\n","    for i, (img_index, similarity) in enumerate(most_similar_images[:5]):\n","        plt.subplot(1, 6, i+2)\n","        plt.imshow(image_friends_second_list[img_index])\n","        plt.title(f'Similarity: {similarity:.5f}%')\n","        plt.axis('off')\n","    plt.show()"],"metadata":{"id":"mKqr0T2Euled"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_model_with_friends_ver1(4, image_friends_first_list, image_friends_second_list, face_embeding_model)"],"metadata":{"id":"mdniMyOqw78w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 함수"],"metadata":{"id":"YbxrXQpsrdil"}},{"cell_type":"code","source":["import tensorflow as tf\n","import mediapipe as mp\n","import numpy as np\n","import os\n","import cv2\n","\n","class FaceEmbedder:\n","    def __init__(self, model_path: str, margin: float = 0.15) :\n","        self.margin = margin  # Adjust this value to change the cropping margin\n","        self.model = tf.keras.models.load_model(model_path)\n","        self.face_detection = mp.solutions.face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5)\n","\n","    def _get_distance(self, embedded_image1, embedded_image2) :\n","        distance = np.linalg.norm(embedded_image1 - embedded_image2)\n","        return distance\n","\n","    def _get_most_similar_vactor(self, distance_list) :\n","        # Compute min and max distances\n","        min_distance = min(distance_list)\n","        max_distance = max(distance_list)\n","        similar_images = []\n","\n","        # Normalize distances and compute similarities\n","        for i, distance in enumerate(distance_list):\n","            # Normalize the distance to [0,1] using the min and max distances\n","            normalized_distance = (distance - 0) / (max_distance - 0)\n","\n","            # Convert to percentage\n","            percentage = (1 - normalized_distance) * 100\n","\n","            # Compute the similarity (as 1 - normalized Euclidean distance)\n","            similarity = percentage\n","\n","            # Add new image\n","            similar_images.append((i, similarity))  # Keeping track of the index and similarity\n","\n","        # Sort the images by similarity in descending order\n","        similar_images.sort(key=lambda x: x[1], reverse=True)\n","\n","        # Return the top 5 most similar images (indices and similarities)\n","        return similar_images[:5]\n","\n","\n","    def _get_face(self, img) :\n","        img = img\n","        face = self.face_detection.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","        if not face.detections:\n","            print('Cant find face')\n","            return None\n","\n","        for detection in face.detections:\n","            # Get bounding box coordinates\n","            box = detection.location_data.relative_bounding_box\n","            ih, iw, _ = img.shape\n","            x, y, w, h = int(box.xmin * iw), int(box.ymin * ih), int(box.width * iw), int(box.height * ih)\n","\n","            # Calculate margins for x, y, w, h\n","            mx = int(w * self.margin)\n","            my = int(h * self.margin)\n","\n","            # Crop the face with margins\n","            face_image = img[y+my:y+h-my, x+mx:x+w-mx]\n","            if face_image.size == 0:\n","                print('Face image size is null')\n","                continue\n","            face_image = cv2.cvtColor(face_image, cv2.COLOR_RGB2GRAY)\n","            return cv2.resize(face_image, (160, 160))\n","\n","        return None\n","\n","    def get_embedded_face(self, face_image) :\n","        img = cv2.imread(face_image)\n","        if img is None:\n","            print(f\"Failed to read image: {face_image}\")\n","            return None\n","\n","        face_image = self._get_face(img)\n","        if face_image is None:\n","            return None\n","\n","        # Preprocess the image\n","        image = cv2.cvtColor(face_image, cv2.COLOR_GRAY2RGB)\n","        image = np.expand_dims(image, axis=0)  # Add batch dimension\n","        image = image.astype('float32') / 255  # Normalize to [0,1]\n","\n","        # Compute embedding\n","        return self.model.predict(image)[0]"],"metadata":{"id":"nu-uNqJBMnjU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embeding = FaceEmbedder(model_path = '/content/drive/MyDrive/A.아이/github/models_folder/facenet/facenet_model.h5')"],"metadata":{"id":"rEI6isXcOJFv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import cv2\n","\n","def test_model_with_friends(index, image_friends_first_list, image_friends_second_list, face_embedder):\n","    # Get the embedding for the anchor image\n","    anchor_image = friends_path_first+image_friends_first_list[index]\n","    anchor_embedding = face_embedder.get_embedded_face(anchor_image)\n","\n","    # Variables to keep track of most similar images\n","    distances = []  # A list to keep track of the distances\n","\n","    # Iterate over images to compute distances\n","    for image in image_friends_second_list:\n","        # Get the embedding for this image\n","        image_embedding = face_embedder.get_embedded_face(friends_path_second+image)\n","\n","        # Compute the distance\n","        if image_embedding is not None:\n","            distance = face_embedder._get_distance(anchor_embedding, image_embedding)\n","            distances.append(distance)\n","        else:\n","            distances.append(float('inf'))  # Handle the case where the face is not detected\n","    # Get the most similar images\n","    most_similar_images = face_embedder._get_most_similar_vactor(distances)\n","\n","    # Show the anchor image\n","    plt.figure(figsize=(20, 4))\n","    plt.subplot(1, 6, 1)\n","    plt.imshow(cv2.cvtColor(cv2.imread(anchor_image), cv2.COLOR_BGR2RGB))\n","    plt.title(\"Anchor image\")\n","    plt.axis('off')\n","\n","    # Show the most similar images\n","    for i, (img_index, similarity) in enumerate(most_similar_images):\n","        similar_image = cv2.imread(friends_path_second+image_friends_second_list[img_index])\n","        plt.subplot(1, 6, i + 2)\n","        plt.imshow(cv2.cvtColor(similar_image, cv2.COLOR_BGR2RGB))\n","        plt.title(f'Similarity: {similarity:.5f}%')\n","        plt.axis('off')\n","    plt.show()\n"],"metadata":{"id":"g6UPOy1JB4rl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_model_with_friends(21, friends_path_first_name, friends_path_second_name, embeding)"],"metadata":{"id":"ujheWpxBEqeP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 정확도"],"metadata":{"id":"8GaMbW7NxgoP"}},{"cell_type":"markdown","source":["## tesnorflow lite model load function"],"metadata":{"id":"rzcqmg5U5lb0"}},{"cell_type":"code","source":["import tensorflow as tf\n","import mediapipe as mp\n","import numpy as np\n","import os\n","import cv2\n","\n","class FaceEmbedder:\n","    def __init__(self, model_path: str, margin: float = 0.15) :\n","        self.margin = margin  # Adjust this value to change the cropping margin\n","\n","        self.interpreter = tf.lite.Interpreter(model_path=model_path)\n","        self.interpreter.allocate_tensors()\n","\n","        self.__input_details = self.interpreter.get_input_details()\n","        self.__output_details = self.interpreter.get_output_details()\n","\n","        self.input_index = self.__input_details[0]['index']\n","        self.output_index = self.__output_details[0]['index']\n","\n","        self.face_detection = mp.solutions.face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5)\n","\n","    def _get_distance(self, embedded_image1, embedded_image2) :\n","        distance = np.linalg.norm(embedded_image1 - embedded_image2)\n","        return distance\n","\n","    def _get_most_similar_vactor(self, distance_list) :\n","        # Compute min and max distances\n","        min_distance = min(distance_list)\n","        max_distance = max(distance_list)\n","        similar_images = []\n","\n","        # Normalize distances and compute similarities\n","        for i, distance in enumerate(distance_list):\n","            # Normalize the distance to [0,1] using the min and max distances\n","            normalized_distance = (distance - 0) / (max_distance - 0)\n","\n","            # Convert to percentage\n","            percentage = (1 - normalized_distance) * 100\n","\n","            # Compute the similarity (as 1 - normalized Euclidean distance)\n","            similarity = percentage\n","\n","            # Add new image\n","            similar_images.append((i, similarity))  # Keeping track of the index and similarity\n","\n","        # Sort the images by similarity in descending order\n","        similar_images.sort(key=lambda x: x[1], reverse=True)\n","\n","        # Return the top 5 most similar images (indices and similarities)\n","        return similar_images[:5]\n","\n","\n","    def _get_face(self, img) :\n","        img = img\n","        face = self.face_detection.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","        if not face.detections:\n","            print('Cant find face')\n","            return None\n","\n","        for detection in face.detections:\n","            # Get bounding box coordinates\n","            box = detection.location_data.relative_bounding_box\n","            ih, iw, _ = img.shape\n","            x, y, w, h = int(box.xmin * iw), int(box.ymin * ih), int(box.width * iw), int(box.height * ih)\n","\n","            # Calculate margins for x, y, w, h\n","            mx = int(w * self.margin)\n","            my = int(h * self.margin)\n","\n","            # Crop the face with margins\n","            face_image = img[y+my:y+h-my, x+mx:x+w-mx]\n","            if face_image.size == 0:\n","                print('Face image size is null')\n","                continue\n","            face_image = cv2.cvtColor(face_image, cv2.COLOR_RGB2GRAY)\n","            return cv2.resize(face_image, (160, 160))\n","\n","        return None\n","\n","    def get_embedded_face(self, face_image) :\n","        img = cv2.imread(face_image)\n","        if img is None:\n","            print(f\"Failed to read image: {face_image}\")\n","            return None\n","\n","        face_image = self._get_face(img)\n","        if face_image is None:\n","            return None\n","\n","        # Preprocess the image\n","        image = cv2.cvtColor(face_image, cv2.COLOR_GRAY2RGB)\n","        image = np.expand_dims(image, axis=0)  # Add batch dimension\n","        image = image.astype('float32') / 255  # Normalize to [0,1]\n","\n","        # Compute embedding\n","        self.interpreter.set_tensor(self.input_index, image)\n","        self.interpreter.invoke()\n","        embeddings = self.interpreter.get_tensor(self.output_index)\n","\n","        return embeddings"],"metadata":{"id":"I_e21rKs5jcE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 정확도 테스트 function"],"metadata":{"id":"ctG1ZtDA5tzp"}},{"cell_type":"code","source":[],"metadata":{"id":"ufquuIKqJJl9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def modified_test_model_with_friends(index, image_friends_first_list, image_friends_second_list, label_first_list, label_second_list, face_embedder):\n","    # Get the embedding for the anchor image\n","    anchor_image = friends_path_first + image_friends_first_list[index]\n","    anchor_embedding = face_embedder.get_embedded_face(anchor_image)\n","\n","    # Variables to keep track of most similar images\n","    distances = []  # A list to keep track of the distances\n","\n","    # Iterate over images to compute distances\n","    for image in image_friends_second_list:\n","        # Get the embedding for this image\n","        image_embedding = face_embedder.get_embedded_face(friends_path_second + image)\n","\n","        # Compute the distance\n","        if image_embedding is not None:\n","            distance = face_embedder._get_distance(anchor_embedding, image_embedding)\n","            distances.append(distance)\n","        else:\n","            distances.append(float('inf'))  # Handle the case where the face is not detected\n","\n","    # Get the most similar images\n","    most_similar_images = face_embedder._get_most_similar_vactor(distances)\n","\n","    # Check if the true label is in the top 3 predictions\n","    true_label = label_first_list[index]\n","    top_3_predictions = [label_second_list[img_index] for img_index, _ in most_similar_images[:3]]\n","    correct_prediction = true_label in top_3_predictions\n","\n","    # Show the anchor image\n","    plt.figure(figsize=(20, 4))\n","    plt.subplot(1, 6, 1)\n","    plt.imshow(cv2.cvtColor(cv2.imread(anchor_image), cv2.COLOR_BGR2RGB))\n","    plt.title(\"Anchor image\")\n","    plt.axis('off')\n","\n","    # Show the most similar images\n","    for i, (img_index, similarity) in enumerate(most_similar_images):\n","        similar_image = cv2.imread(friends_path_second + image_friends_second_list[img_index])\n","        plt.subplot(1, 6, i + 2)\n","        plt.imshow(cv2.cvtColor(similar_image, cv2.COLOR_BGR2RGB))\n","        plt.title(f'Similarity: {similarity:.5f}%')\n","        plt.axis('off')\n","    plt.show()\n","\n","    return correct_prediction\n","\n","def calculate_accuracy(image_friends_first_list, image_friends_second_list, label_first_list, label_second_list, face_embedder):\n","    total_images = len(image_friends_first_list)\n","    correct_predictions = 0\n","\n","    for index in range(total_images):\n","        correct_prediction = modified_test_model_with_friends(index, image_friends_first_list, image_friends_second_list, label_first_list, label_second_list, face_embedder)\n","        if correct_prediction:\n","            correct_predictions += 1\n","\n","    accuracy = correct_predictions / total_images\n","    return accuracy\n","\n","# Example usage:\n","# accuracy = calculate_accuracy(image_friends_first_list, image_friends_second_list, label_first_list, label_second_list, face_embedder)\n","# print(f'Accuracy: {accuracy * 100:.2f}%')"],"metadata":{"id":"03PVACXsxjVx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracy = calculate_accuracy(friends_path_first_name, friends_path_second_name, label_first_list, label_second_list, embeding)\n","print(f'Accuracy: {accuracy * 100:.2f}%')"],"metadata":{"id":"rWjgQBJBxlqm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 모델 경량화"],"metadata":{"id":"N0m-VAgPxrt4"}},{"cell_type":"code","source":["model = tf.keras.models.load_model('/content/drive/MyDrive/A.아이/github/models_folder/facenet/facenet_model.h5')\n","\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","\n","# FP16 양자화 설정\n","converter.target_spec.supported_types = [tf.float16]\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","\n","tflite_model = converter.convert()\n","\n","# 변환된 모델을 .tflite 파일에 저장\n","open(\"/content/drive/MyDrive/A.아이/github/models_folder/facenet/FaceNet_Lite_model.tflite\", \"wb\").write(tflite_model)"],"metadata":{"id":"9PBTbPj0z7jU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LxbTQ5YA3mAH"},"execution_count":null,"outputs":[]}]}