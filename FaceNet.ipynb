{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNHnvsjQecPqB05UVEIqHXG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"lxKyc6-Cjem9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install mtcnn"],"metadata":{"id":"gOioP3mmBbfT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from mtcnn import mtcnn\n","import PIL\n","import numpy as np\n","import os\n","import cv2\n","from google.colab.patches import cv2_imshow"],"metadata":{"id":"w_Lz1hNWuUeV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://jkisaaclee.kro.kr/keras/facenet/deep%20learning/computer%20vision/2019/10/01/how_to_develop_a_face_recognition_system_using_facenet_in_keras_ko/\n","# https://machinelearningmastery.com/how-to-develop-a-face-recognition-system-using-facenet-in-keras-and-an-svm-classifier/"],"metadata":{"id":"LnpuEWiLn6yV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = tf.keras.models.load_model('/content/drive/MyDrive/A.아이/github/models_folder/facenet/facenet_model.h5')"],"metadata":{"id":"IZcuWwMDsoTz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model.input)\n","print(model.output)"],"metadata":{"id":"fk1NfRxzs9Nd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install mtcnn\n","!pip install mediapipe"],"metadata":{"id":"wAyayPJPtNQd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["friends_path_first = '/content/drive/MyDrive/A.아이/images/friends_image/fist_image/'\n","friends_path_first_name = os.listdir(friends_path_first)\n","\n","friends_path_second = '/content/drive/MyDrive/A.아이/images/friends_image/second_image/'\n","friends_path_second_name = os.listdir(friends_path_second)"],"metadata":{"id":"1QKnFP4eog2t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import mediapipe as mp\n","\n","mp_face_detection = mp.solutions.face_detection\n","image_friends_first_list = []\n","margin = 0.15  # Adjust this value to change the cropping margin\n","\n","for name in friends_path_first_name :\n","    img = cv2.imread(friends_path_first + name)\n","    with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5) as face_detection:\n","            face = face_detection.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","            if face.detections:\n","                for i, detection in enumerate(face.detections):\n","                    # Get bounding box coordinates\n","                    box = detection.location_data.relative_bounding_box\n","                    ih, iw, _ = img.shape\n","                    x, y, w, h = int(box.xmin * iw), int(box.ymin * ih), int(box.width * iw), int(box.height * ih)\n","\n","                    # Calculate margins for x, y, w, h\n","                    mx = int(w * margin)\n","                    my = int(h * margin)\n","\n","                    # Crop the face with margins\n","                    face_image = img[y+my:y+h-my, x+mx:x+w-mx]\n","                    if face_image.size != 0:\n","                        # Resize the image to 105x105\n","                        face_image = cv2.resize(face_image, (160, 160))\n","                        face_image = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)\n","                    else :\n","                        break\n","            else :\n","                print('cant find face')\n","                continue\n","    image_friends_first_list.append(face_image)\n","\n","for i in image_friends_first_list :\n","    cv2_imshow(i)\n"],"metadata":{"id":"NHxFrUqvqO4-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mp_face_detection = mp.solutions.face_detection\n","image_friends_second_list = []\n","margin = 0.15  # Adjust this value to change the cropping margin\n","\n","for name in friends_path_second_name :\n","    img = cv2.imread(friends_path_second + name)\n","    with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5) as face_detection:\n","            face = face_detection.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","            if face.detections:\n","                for i, detection in enumerate(face.detections):\n","                    # Get bounding box coordinates\n","                    box = detection.location_data.relative_bounding_box\n","                    ih, iw, _ = img.shape\n","                    x, y, w, h = int(box.xmin * iw), int(box.ymin * ih), int(box.width * iw), int(box.height * ih)\n","\n","                    # Calculate margins for x, y, w, h\n","                    mx = int(w * margin)\n","                    my = int(h * margin)\n","\n","                    # Crop the face with margins\n","                    face_image = img[y+my:y+h-my, x+mx:x+w-mx]\n","                    if face_image.size != 0:\n","                        # Resize the image to 105x105\n","                        face_image = cv2.resize(face_image, (160, 160))\n","                        face_image = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)\n","                    else :\n","                        break\n","            else :\n","                print('cant find face')\n","                continue\n","    image_friends_second_list.append(face_image)\n","\n","for count,i in enumerate(image_friends_second_list) :\n","    print(count)\n","    cv2_imshow(i)\n"],"metadata":{"id":"a1Sxs3FhoaXV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_friends_first_list = np.array(image_friends_first_list)\n","image_friends_second_list = np.array(image_friends_second_list)\n","\n","image_friends_first_list.shape, image_friends_second_list.shape"],"metadata":{"id":"EPcy35n2qsJo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["face_embeding_model = tf.keras.models.load_model('/content/drive/MyDrive/A.아이/github/models_folder/facenet/facenet_model.h5')"],"metadata":{"id":"i7BC9mh7quVs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def get_face_embedding(image, model):\n","    # Preprocess the image\n","    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n","    image = np.expand_dims(image, axis=0)  # Add batch dimension\n","    image = image.astype('float32') / 255  # Normalize to [0,1]\n","\n","    # Compute embedding\n","    embedding = model.predict(image)[0]\n","    return embedding\n","\n","def test_model_with_friends(index, image_friends_first_list, image_friends_second_list, model):\n","    # Get the embedding for the anchor image\n","    anchor_embedding = get_face_embedding(image_friends_first_list[index], model)\n","\n","    # Variables to keep track of most similar images\n","    most_similar_images = []  # A list to keep track of the indices of the most similar images\n","    distances = []  # A list to keep track of the distances\n","\n","    # Iterate over images to compute distances\n","    for i, image in enumerate(image_friends_second_list):\n","        # Get the embedding for this image\n","        image_embedding = get_face_embedding(image, model)\n","\n","        # Compute the distance\n","        distance = np.linalg.norm(anchor_embedding - image_embedding)\n","        distances.append(distance)\n","\n","    # Compute min and max distances\n","    min_distance = min(distances)\n","    max_distance = max(distances)\n","\n","    # Normalize distances and compute similarities\n","    for i, distance in enumerate(distances):\n","        # Normalize the distance to [0,1] using the min and max distances\n","        normalized_distance = (distance - 0) / (max_distance - 0)\n","\n","        # Convert to percentage\n","        percentage = (1 - normalized_distance) * 100\n","\n","        # Compute the similarity (as 1 - normalized Euclidean distance)\n","        similarity = percentage\n","\n","        # Add new image\n","        most_similar_images.append((i, similarity))  # Keeping track of the index and similarity\n","\n","    # Sort the images by similarity\n","    most_similar_images.sort(key=lambda x: x[1], reverse=True)\n","\n","    # Show the anchor image\n","    plt.figure(figsize=(20, 4))\n","    plt.subplot(1, 6, 1)\n","    plt.imshow(image_friends_first_list[index])\n","    plt.title(\"Anchor image\")\n","    plt.axis('off')\n","\n","    # Show the most similar images\n","    for i, (img_index, similarity) in enumerate(most_similar_images[:5]):\n","        plt.subplot(1, 6, i+2)\n","        plt.imshow(image_friends_second_list[img_index])\n","        plt.title(f'Similarity: {similarity:.5f}%')\n","        plt.axis('off')\n","    plt.show()"],"metadata":{"id":"mKqr0T2Euled"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_model_with_friends(4, image_friends_first_list, image_friends_second_list, face_embeding_model)"],"metadata":{"id":"mdniMyOqw78w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from mtcnn import mtcnn\n","import tensorflow as tf\n","import mediapipe as mp\n","import PIL\n","import numpy as np\n","import os\n","import cv2\n","\n","class get_embeding_vector() :\n","    def __init__(self) :\n","        self.mp_face_detection = mp.solutions.face_detection\n","        self.margin = 0.15  # Adjust this value to change the cropping margin\n","        self.model = tf.keras.models.load_model('/content/drive/MyDrive/A.아이/github/models_folder/facenet/facenet_model.h5')\n","\n","    def get_face(self, image) :\n","        img = cv2.imread(image)\n","        with self.mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5) as face_detection:\n","                face = face_detection.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","                if face.detections:\n","                    for detection in face.detections :\n","                        # Get bounding box coordinates\n","                        box = detection.location_data.relative_bounding_box\n","                        ih, iw, _ = img.shape\n","                        x, y, w, h = int(box.xmin * iw), int(box.ymin * ih), int(box.width * iw), int(box.height * ih)\n","\n","                        # Calculate margins for x, y, w, h\n","                        mx = int(w * self.margin)\n","                        my = int(h * self.margin)\n","\n","                        # Crop the face with margins\n","                        face_image = img[y+my:y+h-my, x+mx:x+w-mx]\n","                        if face_image.size != 0:\n","                            # Resize the image to 105x105\n","                            face_image = cv2.resize(face_image, (160, 160))\n","                            face_image = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)\n","                        else :\n","                            print('face image size is null')\n","                            break\n","                else :\n","                    print('cant find face')\n","        return face_image\n","\n","    def get_embeded_face(self, face_image) :\n","        # Preprocess the image\n","        image = cv2.cvtColor(face_image, cv2.COLOR_GRAY2RGB)\n","        image = np.expand_dims(image, axis=0)  # Add batch dimension\n","        image = image.astype('float32') / 255  # Normalize to [0,1]\n","\n","        # Compute embedding\n","        embedding = self.model.predict(image)[0]\n","\n","        return embedding"],"metadata":{"id":"4bm18_wUw_nO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["face_embeding = get_embeding_vector()"],"metadata":{"id":"4whUwy6GMUld"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["face_embeding.get_embeded_face(image_friends_first_list[0])"],"metadata":{"id":"1_QU4MMTMbwc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from mtcnn import MTCNN\n","import tensorflow as tf\n","import mediapipe as mp\n","import PIL\n","import numpy as np\n","import os\n","import cv2\n","from typing import Optional\n","\n","class FaceEmbedder:\n","    def __init__(self, model_path: str, margin: float = 0.15) :\n","        self.margin = margin  # Adjust this value to change the cropping margin\n","        self.model = tf.keras.models.load_model(model_path)\n","        self.face_detection = mp.solutions.face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5)\n","\n","    def _get_face(self, img) -> Optional[np.ndarray]:\n","        img = cv2.imread(img)\n","        face = self.face_detection.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","        if not face.detections:\n","            print('Cant find face')\n","            return None\n","\n","        for detection in face.detections:\n","            # Get bounding box coordinates\n","            box = detection.location_data.relative_bounding_box\n","            ih, iw, _ = img.shape\n","            x, y, w, h = int(box.xmin * iw), int(box.ymin * ih), int(box.width * iw), int(box.height * ih)\n","\n","            # Calculate margins for x, y, w, h\n","            mx = int(w * self.margin)\n","            my = int(h * self.margin)\n","\n","            # Crop the face with margins\n","            face_image = img[y+my:y+h-my, x+mx:x+w-mx]\n","            if face_image.size == 0:\n","                print('Face image size is null')\n","                continue\n","\n","            # Resize the image to 105x105\n","            return cv2.resize(face_image, (160, 160))\n","\n","        return None\n","\n","    def get_embedded_face(self, face_image) -> Optional[np.ndarray]:\n","        img = cv2.cvtColor(face_image, cv2.COLOR_GRAY2RGB)\n","        if img is None:\n","            print(f\"Failed to read image: {face_image}\")\n","            return None\n","\n","        face_image = self._get_face(img)\n","        if face_image is None:\n","            return None\n","\n","        # Preprocess the image\n","        image = np.expand_dims(face_image, axis=0)  # Add batch dimension\n","        image = image.astype('float32') / 255  # Normalize to [0,1]\n","\n","        # Compute embedding\n","        return self.model.predict(image)[0]\n"],"metadata":{"id":"nu-uNqJBMnjU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embeding = FaceEmbedder(model_path = '/content/drive/MyDrive/A.아이/github/models_folder/facenet/facenet_model.h5')"],"metadata":{"id":"rEI6isXcOJFv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embeding.get_embedded_face(image_friends_first_list[0])"],"metadata":{"id":"L3hBiyb8OT_c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GFBrx9znPTan"},"execution_count":null,"outputs":[]}]}